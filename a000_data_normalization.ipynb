{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708f84c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting dataset normalization process...\n",
      "Normalization formula: col_norm = col / max(abs(col_all_datasets))\n",
      "Expected range: [-1, 1]\n",
      "\n",
      "Found 19 CSV files:\n",
      "  - motor_simulation_Trj_5_e4.csv\n",
      "  - motor_simulation_Trj_1_e0.csv\n",
      "  - motor_simulation_Trj_1_e1.csv\n",
      "  - motor_simulation_Trj_3_e0.csv\n",
      "  - motor_simulation_Trj_3_e1.csv\n",
      "  - motor_simulation_Trj_2_e1.csv\n",
      "  - motor_simulation_Trj_4_e1.csv\n",
      "  - motor_simulation_Trj_2_e0.csv\n",
      "  - motor_simulation_Trj_4_e2.csv\n",
      "  - motor_simulation_Trj_2_e2.csv\n",
      "  - motor_simulation_Trj_1_e3.csv\n",
      "  - motor_simulation_Trj_5_e2.csv\n",
      "  - motor_simulation_Trj_5_e0.csv\n",
      "  - motor_simulation_Trj_1_e2.csv\n",
      "  - motor_simulation_Trj_5_e1.csv\n",
      "  - motor_simulation_Trj_4_e0.csv\n",
      "  - motor_simulation_Trj_5_e3.csv\n",
      "  - motor_simulation_Trj_4_e3.csv\n",
      "  - motor_simulation_Trj_3_e2.csv\n",
      "\n",
      "Step 1: Loading all datasets to find global absolute maxima...\n",
      "  Loaded motor_simulation_Trj_5_e4.csv: 10001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_1_e0.csv: 18001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_1_e1.csv: 12001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_3_e0.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_3_e1.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_2_e1.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_4_e1.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_2_e0.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_4_e2.csv: 10001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_2_e2.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_1_e3.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_5_e2.csv: 10001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_5_e0.csv: 15001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_1_e2.csv: 15001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_5_e1.csv: 8001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_4_e0.csv: 15001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_5_e3.csv: 5001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_4_e3.csv: 5001 rows, 10 columns\n",
      "  Loaded motor_simulation_Trj_3_e2.csv: 8001 rows, 10 columns\n",
      "\n",
      "Combining 19 datasets (187019 total rows)...\n",
      "\n",
      "Global absolute maxima across all datasets:\n",
      "============================================================\n",
      "Id_current     : max(abs) =   310.953400 | range: [-310.953,   22.788]\n",
      "Iq_current     : max(abs) =   325.281400 | range: [   0.000,  325.281]\n",
      "speed_rpm      : max(abs) = 15217.464000 | range: [1224.269, 15217.464]\n",
      "voltage        : max(abs) =   100.000000 | range: [  10.000,  100.000]\n",
      "Tmagout_real   : max(abs) =    89.892930 | range: [  24.934,   89.893]\n",
      "Tmagin_real    : max(abs) =   109.357500 | range: [  24.879,  109.358]\n",
      "Twindoutlet_real: max(abs) =   130.379650 | range: [  24.813,  130.380]\n",
      "Twindinlet_real: max(abs) =   114.243750 | range: [  25.333,  114.244]\n",
      "Twinding_real  : max(abs) =   124.625490 | range: [  25.101,  124.625]\n",
      "TPM_real       : max(abs) =   123.139160 | range: [  25.039,  123.139]\n",
      "============================================================\n",
      "\n",
      "Created/verified output folder: test_norm/\n",
      "\n",
      "Step 2: Normalizing and saving datasets...\n",
      "  motor_simulation_Trj_5_e4.csv -> motor_simulation_Trj_5_e4_norm.csv | Shape: (10001, 10) | Range: [ 0.0000,  1.0000]\n",
      "  motor_simulation_Trj_1_e0.csv -> motor_simulation_Trj_1_e0_norm.csv | Shape: (18001, 10) | Range: [-0.5620,  0.9312]\n",
      "  motor_simulation_Trj_1_e1.csv -> motor_simulation_Trj_1_e1_norm.csv | Shape: (12001, 10) | Range: [-0.2973,  0.9038]\n",
      "  motor_simulation_Trj_3_e0.csv -> motor_simulation_Trj_3_e0_norm.csv | Shape: (8001, 10) | Range: [-0.8011,  1.0000]\n",
      "  motor_simulation_Trj_3_e1.csv -> motor_simulation_Trj_3_e1_norm.csv | Shape: (8001, 10) | Range: [-0.8011,  1.0000]\n",
      "  motor_simulation_Trj_2_e1.csv -> motor_simulation_Trj_2_e1_norm.csv | Shape: (8001, 10) | Range: [-0.5620,  0.7497]\n",
      "  motor_simulation_Trj_4_e1.csv -> motor_simulation_Trj_4_e1_norm.csv | Shape: (8001, 10) | Range: [-0.4581,  0.7337]\n",
      "  motor_simulation_Trj_2_e0.csv -> motor_simulation_Trj_2_e0_norm.csv | Shape: (8001, 10) | Range: [-0.5620,  0.7497]\n",
      "  motor_simulation_Trj_4_e2.csv -> motor_simulation_Trj_4_e2_norm.csv | Shape: (10001, 10) | Range: [-0.5058,  0.7290]\n",
      "  motor_simulation_Trj_2_e2.csv -> motor_simulation_Trj_2_e2_norm.csv | Shape: (8001, 10) | Range: [-0.5620,  0.7497]\n",
      "  motor_simulation_Trj_1_e3.csv -> motor_simulation_Trj_1_e3_norm.csv | Shape: (8001, 10) | Range: [-0.4254,  0.7756]\n",
      "  motor_simulation_Trj_5_e2.csv -> motor_simulation_Trj_5_e2_norm.csv | Shape: (10001, 10) | Range: [-0.0231,  1.0000]\n",
      "  motor_simulation_Trj_5_e0.csv -> motor_simulation_Trj_5_e0_norm.csv | Shape: (15001, 10) | Range: [-0.0009,  0.5000]\n",
      "  motor_simulation_Trj_1_e2.csv -> motor_simulation_Trj_1_e2_norm.csv | Shape: (15001, 10) | Range: [-1.0000,  1.0000]\n",
      "  motor_simulation_Trj_5_e1.csv -> motor_simulation_Trj_5_e1_norm.csv | Shape: (8001, 10) | Range: [-0.0445,  1.0000]\n",
      "  motor_simulation_Trj_4_e0.csv -> motor_simulation_Trj_4_e0_norm.csv | Shape: (15001, 10) | Range: [-0.4581,  0.7337]\n",
      "  motor_simulation_Trj_5_e3.csv -> motor_simulation_Trj_5_e3_norm.csv | Shape: (5001, 10) | Range: [-0.0875,  1.0000]\n",
      "  motor_simulation_Trj_4_e3.csv -> motor_simulation_Trj_4_e3_norm.csv | Shape: (5001, 10) | Range: [-0.5862,  0.9379]\n",
      "  motor_simulation_Trj_3_e2.csv -> motor_simulation_Trj_3_e2_norm.csv | Shape: (8001, 10) | Range: [-0.8011,  1.0000]\n",
      "\n",
      "Normalization complete!\n",
      "‚úÖ Successfully processed: 19/19 files\n",
      "üìÅ Normalized datasets saved in test_norm/\n",
      "\n",
      "Summary:\n",
      "- Input folder: test/\n",
      "- Output folder: test_norm/\n",
      "- Files processed: 19/19\n",
      "- Total rows processed: 187,019\n",
      "- Columns: ['Id_current', 'Iq_current', 'speed_rpm', 'voltage', 'Tmagout_real', 'Tmagin_real', 'Twindoutlet_real', 'Twindinlet_real', 'Twinding_real', 'TPM_real']\n",
      "- Normalization: col_norm = col / max(abs(col_all_datasets))\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: Checking normalization correctness\n",
      "======================================================================\n",
      "Found 19 normalized files\n",
      "‚úÖ motor_simulation_Trj_5_e2_norm.csv | Range: [-0.0231,  1.0000]\n",
      "‚úÖ motor_simulation_Trj_1_e0_norm.csv | Range: [-0.5620,  0.9312]\n",
      "‚úÖ motor_simulation_Trj_5_e3_norm.csv | Range: [-0.0875,  1.0000]\n",
      "... and 16 more files\n",
      "\n",
      "Detailed statistics for: motor_simulation_Trj_5_e2_norm.csv\n",
      "Shape: (10001, 10)\n",
      "\n",
      "Column ranges (should be within [-1, 1]):\n",
      "  Id_current     : [-0.0231, -0.0231] ‚úÖ\n",
      "  Iq_current     : [ 0.1521,  0.1521] ‚úÖ\n",
      "  speed_rpm      : [ 0.0805,  0.7918] ‚úÖ\n",
      "  voltage        : [ 0.1016,  1.0000] ‚úÖ\n",
      "  Tmagout_real   : [ 0.2774,  0.5834] ‚úÖ\n",
      "  Tmagin_real    : [ 0.2275,  0.5534] ‚úÖ\n",
      "  Twindoutlet_real: [ 0.1903,  0.3097] ‚úÖ\n",
      "  Twindinlet_real: [ 0.2217,  0.3522] ‚úÖ\n",
      "  Twinding_real  : [ 0.2015,  0.3237] ‚úÖ\n",
      "  TPM_real       : [ 0.2034,  0.5356] ‚úÖ\n",
      "\n",
      "üéâ Process completed successfully!\n",
      "All normalized values are within [-1, 1] range.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def normalize_datasets():\n",
    "    \"\"\"\n",
    "    Load all CSV files from EM_data/, find global absolute maxima across all datasets,\n",
    "    normalize each dataset by global absolute maxima, and save to EM_data_norm/\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all CSV files in EM_data folder\n",
    "    input_folder = 'test'\n",
    "    csv_pattern = os.path.join(input_folder, '*.csv')\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {input_folder}/ folder!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"  - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Step 1: Load all datasets and concatenate to find global absolute maxima\n",
    "    print(\"\\nStep 1: Loading all datasets to find global absolute maxima...\")\n",
    "    all_data = []\n",
    "    total_rows = 0\n",
    "    \n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            all_data.append(df)\n",
    "            total_rows += len(df)\n",
    "            print(f\"  Loaded {os.path.basename(file)}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No datasets loaded successfully!\")\n",
    "        return\n",
    "    \n",
    "    # Concatenate all data to find global absolute maxima\n",
    "    print(f\"\\nCombining {len(all_data)} datasets ({total_rows} total rows)...\")\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Find maximum of absolute values for each column\n",
    "    global_abs_max = combined_data.abs().max()\n",
    "    \n",
    "    print(f\"\\nGlobal absolute maxima across all datasets:\")\n",
    "    print(\"=\" * 60)\n",
    "    for col, max_val in global_abs_max.items():\n",
    "        min_val = combined_data[col].min()\n",
    "        max_val_orig = combined_data[col].max()\n",
    "        print(f\"{col:15}: max(abs) = {max_val:12.6f} | range: [{min_val:8.3f}, {max_val_orig:8.3f}]\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 2: Create output folder\n",
    "    output_folder = 'test_norm'\n",
    "    Path(output_folder).mkdir(exist_ok=True)\n",
    "    print(f\"\\nCreated/verified output folder: {output_folder}/\")\n",
    "    \n",
    "    # Step 3: Normalize each dataset and save\n",
    "    print(f\"\\nStep 2: Normalizing and saving datasets...\")\n",
    "    \n",
    "    successful_files = 0\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # Load dataset\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Normalize by global absolute maxima (element-wise division)\n",
    "            df_norm = df / global_abs_max\n",
    "            \n",
    "            # Verify normalization (all values should be between -1 and 1)\n",
    "            assert (df_norm >= -1.001).all().all(), f\"Values < -1 found in {file}\"  # Small tolerance for floating point\n",
    "            assert (df_norm <= 1.001).all().all(), f\"Values > 1 found in {file}\"   # Small tolerance for floating point\n",
    "            \n",
    "            # Create output filename\n",
    "            filename = os.path.basename(file)\n",
    "            name_without_ext = os.path.splitext(filename)[0]\n",
    "            output_filename = f\"{name_without_ext}_norm.csv\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            \n",
    "            # Save normalized dataset\n",
    "            df_norm.to_csv(output_path, index=False)\n",
    "            \n",
    "            # Print statistics\n",
    "            min_val = df_norm.min().min()\n",
    "            max_val = df_norm.max().max()\n",
    "            print(f\"  {filename:25} -> {output_filename:30} | Shape: {df_norm.shape} | Range: [{min_val:7.4f}, {max_val:7.4f}]\")\n",
    "            \n",
    "            successful_files += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nNormalization complete!\")\n",
    "    print(f\"‚úÖ Successfully processed: {successful_files}/{len(csv_files)} files\")\n",
    "    print(f\"üìÅ Normalized datasets saved in {output_folder}/\")\n",
    "    \n",
    "    # Step 4: Verification summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"- Input folder: {input_folder}/\")\n",
    "    print(f\"- Output folder: {output_folder}/\")\n",
    "    print(f\"- Files processed: {successful_files}/{len(csv_files)}\")\n",
    "    print(f\"- Total rows processed: {total_rows:,}\")\n",
    "    print(f\"- Columns: {list(global_abs_max.index)}\")\n",
    "    print(f\"- Normalization: col_norm = col / max(abs(col_all_datasets))\")\n",
    "    \n",
    "    return global_abs_max\n",
    "\n",
    "def verify_normalization():\n",
    "    \"\"\"\n",
    "    Verify that normalization was done correctly by checking a few samples\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VERIFICATION: Checking normalization correctness\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get normalized files\n",
    "    norm_files = glob.glob('test_norm/*_norm.csv')\n",
    "    \n",
    "    if not norm_files:\n",
    "        print(\"No normalized files found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(norm_files)} normalized files\")\n",
    "    \n",
    "    # Check all files for range compliance\n",
    "    all_in_range = True\n",
    "    for norm_file in norm_files[:3]:  # Check first 3 files as samples\n",
    "        df_norm = pd.read_csv(norm_file)\n",
    "        min_val = df_norm.min().min()\n",
    "        max_val = df_norm.max().max()\n",
    "        \n",
    "        in_range = (-1.001 <= min_val <= 1.001) and (-1.001 <= max_val <= 1.001)\n",
    "        status = \"‚úÖ\" if in_range else \"‚ùå\"\n",
    "        \n",
    "        print(f\"{status} {os.path.basename(norm_file):30} | Range: [{min_val:7.4f}, {max_val:7.4f}]\")\n",
    "        \n",
    "        if not in_range:\n",
    "            all_in_range = False\n",
    "    \n",
    "    if len(norm_files) > 3:\n",
    "        print(f\"... and {len(norm_files) - 3} more files\")\n",
    "    \n",
    "    # Detailed check on first file\n",
    "    if norm_files:\n",
    "        sample_file = norm_files[0]\n",
    "        df_norm = pd.read_csv(sample_file)\n",
    "        \n",
    "        print(f\"\\nDetailed statistics for: {os.path.basename(sample_file)}\")\n",
    "        print(f\"Shape: {df_norm.shape}\")\n",
    "        print(f\"\\nColumn ranges (should be within [-1, 1]):\")\n",
    "        for col in df_norm.columns:\n",
    "            min_val = df_norm[col].min()\n",
    "            max_val = df_norm[col].max()\n",
    "            status = \"‚úÖ\" if (-1.001 <= min_val <= 1.001) and (-1.001 <= max_val <= 1.001) else \"‚ùå\"\n",
    "            print(f\"  {col:15}: [{min_val:7.4f}, {max_val:7.4f}] {status}\")\n",
    "    \n",
    "    return all_in_range\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting dataset normalization process...\")\n",
    "    print(\"Normalization formula: col_norm = col / max(abs(col_all_datasets))\")\n",
    "    print(\"Expected range: [-1, 1]\\n\")\n",
    "    \n",
    "    # Run normalization\n",
    "    global_maxima = normalize_datasets()\n",
    "    \n",
    "    if global_maxima is not None:\n",
    "        # Run verification\n",
    "        verification_passed = verify_normalization()\n",
    "        \n",
    "        if verification_passed:\n",
    "            print(f\"\\nüéâ Process completed successfully!\")\n",
    "            print(f\"All normalized values are within [-1, 1] range.\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Process completed with warnings!\")\n",
    "            print(f\"Some values may be outside expected range.\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Process failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
